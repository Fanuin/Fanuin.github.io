glm( y~x1+x2,data=df,family="binomial")
glm( y~t+x1,data=df,family="binomial")
set.seed(42)
x1 <- rnorm(1000)           # some continuous variables
#x2 <- rnorm(1000)
z1 <- 2*x1 + rnorm(1000)
#z = 1 + 2*x1 + 3*x2
z2 = 1/(1+exp(-z))
t = rbinom(1000,1,pr) #binary treatment
y = 1+5*t + 3*x1      # bernoulli response variable
#now feed it to glm:
df = data.frame(y=y,x1=x1,t=t)
glm( y~t+x1,data=df,family="binomial")
lm( y~t+x1,data=df)
set.seed(42)
x1 <- rnorm(1000)           # some continuous variables
#x2 <- rnorm(1000)
z1 <- 2*x1 + rnorm(1000)
#z = 1 + 2*x1 + 3*x2
z2 = 1/(1+exp(-z))
t = rbinom(1000,1,pr) #binary treatment
y = 1+5*t + 3*x1 + rnorm(1000) #dependent variable
#now feed it to glm:
df = data.frame(y=y,x1=x1,t=t)
lm( y~t+x1,data=df)
lm( y~t,data=df)
t1 <- df[which(df$t==1),]
t0 <- df[which(df$t==0),]
df_t1 <- df[which(df$t==1),]
df_t0 <- df[which(df$t==0),]
est_t1 <- lm( y~t,data=df_71)
est_t1 <- lm( y~t,data=df_t1)
est_t1
est_t1 <- lm( y~x1,data=df_t1)
est_t1
est_t0 <- lm( y~x1,data=df_t0)
est_t0
yhat_t1 <- predict(est_t1)
yhat_t0 <- predict(est_t0)
effect <- mean(yhat_t1) - mean(yhat_t0)
effect
yhat_t0_dft1 <- predict(est_t0, data=df_t1)
effect2 <- mean(yhat_t1) - mean(yhat_t0_dft1)
effect2
yhat_t0_dft1 <- predict(est_t0, newdata=df_t1)
effect2 <- mean(yhat_t1) - mean(yhat_t0_dft1)
effect2
lm( y~t+x1,data=df)
#Causality: Intuition about the T-Learner
#simulate data
set.seed(42)
x1 <- rnorm(1000)           # some continuous variables
#x2 <- rnorm(1000)
z1 <- 2*x1 + rnorm(1000)
#z = 1 + 2*x1 + 3*x2
z2 = 1/(1+exp(-z))
t = rbinom(1000,1,pr) #binary treatment
y = 1+5*t + 3*x1 + rnorm(1000) #dependent variable
#now feed it to glm:
df = data.frame(y=y,x1=x1,t=t)
#how to get a graphical representation of the underlying data, without knowing the mechanism
#pcalg
#We see, that a linear regression is sufficient to estimate the causal effect from t on y
#s-learner----------
lm( y~t+x1,data=df)
#Causality: Intuition about the T-Learner
#simulate data
set.seed(42)
x1 <- rnorm(1000)           # some continuous variables
#x2 <- rnorm(1000)
z1 <- 2*x1 + rnorm(1000)
#z = 1 + 2*x1 + 3*x2
z2 = 1/(1+exp(-z))
t = rbinom(1000,1,pr) #binary treatment
y = 1+5*t + 3*x1 + rnorm(1000) #dependent variable
#now feed it to glm:
df = data.frame(y=y,x1=x1,t=t)
#how to get a graphical representation of the underlying data, without knowing the mechanism
#pcalg
#We see, that a linear regression is sufficient to estimate the causal effect from t on y
#s-learner----------
lm( y~t+x1,data=df)
#Causality: Intuition about the T-Learner
#simulate data
set.seed(42)
x1 <- rnorm(1000)           # some continuous variables
#x2 <- rnorm(1000)
z1 <- 2*x1 + rnorm(1000)
#z = 1 + 2*x1 + 3*x2
z2 = 1/(1+exp(-z))
t = rbinom(1000,1,pr) #binary treatment
y = 1+5*t + 3*x1 + rnorm(1000) #dependent variable
#now feed it to glm:
df = data.frame(y=y,x1=x1,t=t)
#Causality: Intuition about the T-Learner
#simulate data
set.seed(42)
x1 <- rnorm(1000)           # some continuous variables
#x2 <- rnorm(1000)
z1 <- 2*x1 + rnorm(1000)
#z = 1 + 2*x1 + 3*x2
z2 = 1/(1+exp(-z1))
t = rbinom(1000,1,pr) #binary treatment
#Causality: Intuition about the T-Learner
#simulate data
set.seed(42)
x1 <- rnorm(1000)           # some continuous variables
#x2 <- rnorm(1000)
z1 <- 2*x1 + rnorm(1000)
#z = 1 + 2*x1 + 3*x2
z2 = 1/(1+exp(-z1))
t = rbinom(1000,1,z2) #binary treatment
y = 1+5*t + 3*x1 + rnorm(1000)
df = data.frame(y=y,x1=x1,t=t)
lm( y~t+x1,data=df)
glm(t ~ x1, data = df, family = "binomial")
exp(1.70898)
lm(t ~ x1, data = df)
lm( y~t+x1,data=df)
df_t1 <- df[which(df$t==1),]
df_t0 <- df[which(df$t==0),]
est_t1 <- lm( y~x1,data=df_t1)
est_t0 <- lm( y~x1,data=df_t0)
yhat_t1 <- predict(est_t1)
yhat_t0 <- predict(est_t0)
effect <- mean(yhat_t1) - mean(yhat_t0)
#effect is biased!
yhat_t0_dft1 <- predict(est_t0, newdata=df_t1)
effect2 <- mean(yhat_t1) - mean(yhat_t0_dft1)
effect2
yhat_t1_dft0 <- (predict(est_t1, newdata=dft0))
df_t1 <- df[which(df$t==1),]
df_t0 <- df[which(df$t==0),]
est_t1 <- lm( y~x1,data=df_t1)
est_t0 <- lm( y~x1,data=df_t0)
yhat_t1 <- predict(est_t1)
yhat_t0 <- predict(est_t0)
effect <- mean(yhat_t1) - mean(yhat_t0)
#effect is biased!
yhat_t0_dft1 <- predict(est_t0, newdata=df_t1)
effect2 <- mean(yhat_t1) - mean(yhat_t0_dft1)
#correct treatment effect
#x-learner
yhat_t1_dft0 <- (predict(est_t1, newdata=dft0))
yhat_t1_dft0 <- (predict(est_t1, newdata=df_t0))
effect3 <-  mean(yhat_t1_dft0) - mean(yhat_t0)
effect2
effect3
install.packages("remotes")
remotes::install_github("soerenkuenzel/causalToolbox")
library(causalToolbox)
remotes::install_github("soerenkuenzel/causalToolbox")
if (!require("devtools")) install.packages("devtools")
devtools::install_github("soerenkuenzel/causalToolbox")
library(causalToolbox)
remotes::install_github("soerenkuenzel/causalToolbox")
if (!require("devtools")) install.packages("devtools")
devtools::install_github("soerenkuenzel/causalToolbox")
library(causalToolbox)
s_out <- S_BART(feat=df$x1, tr=df$t, yobs=df$y)
x2 <- rnorm(1000)
#Causality: Intuition about the T-Learner
#simulate data
set.seed(42)
x1 <- rnorm(1000)           # some continuous variables
x2 <- rnorm(1000)
z1 <- 2*x1 + rnorm(1000)
#z = 1 + 2*x1 + 3*x2
z2 = 1/(1+exp(-z1))
t = rbinom(1000,1,z2) #binary treatment
y = 1+5*t + 3*x1 +0.5*x2 + rnorm(1000) #dependent variable
#now feed it to glm:
df = data.frame(y=y,x1=x1, x2=x2, t=t)
lm( y~t+x1+x2,data=df)
df_t1 <- df[which(df$t==1),]
df_t0 <- df[which(df$t==0),]
est_t1 <- lm( y~x1+x2,data=df_t1)
est_t0 <- lm( y~x1+x2,data=df_t0)
yhat_t1 <- predict(est_t1)
yhat_t0 <- predict(est_t0)
effect <- mean(yhat_t1) - mean(yhat_t0)
#effect is biased!
effect
yhat_t0_dft1 <- predict(est_t0, newdata=df_t1)
effect2 <- mean(yhat_t1) - mean(yhat_t0_dft1)
#correct treatment effect
#x-learner
yhat_t1_dft0 <- (predict(est_t1, newdata=df_t0))
effect2
effect3 <-  mean(yhat_t1_dft0) - mean(yhat_t0)
effect3
s_out <- S_BART(feat=df[,2:3], tr=df$t, yobs=df$y)
s_out
t_out <- T_BART(feat=df[,2:3], tr=df$t, yobs=df$y)
x_out <- X_BART(feat=df[,2:3], tr=df$t, yobs=df$y)
t_out
s_cate <- EstimateCate(x_out, df)
s_cate <- EstimateCate(x_out)
s_out <- S_RF(feat=df[,2:3], tr=df$t, yobs=df$y)
s_cate <- EstimateCate(x_out)
s_out <- S_RF(feat=df[,2:3], tr=df$t, yobs=df$y)
s_cate <- EstimateCate(s_out)
s_cate <- EstimateCate(s_out, df)
t_out <- T_BART(feat=df[,2:3], tr=df$t, yobs=df$y)
EstimateCate(t_out, df)
t_out <- S_RF(feat=df[,2:3], tr=df$t, yobs=df$y)
t_cate <- EstimateCate(t_out, df)
df_test <- cbind(df[,2:3], df$t, df$y)
s_cate <- EstimateCate(s_out, df_test)
df_test <- cbind(df[,2:3], t, y)
s_cate <- EstimateCate(s_out, df_test)
df = data.frame(x1=x1, x2=x2, t=t, y=y)
#s-learner----------
lm( y~t+x1+x2,data=df)
#However, what if the data structure is more complex?
lm( y~t,data=df)
#Biased estimate if confounder x is left out!
#t-Learner estimate correlational structure of confounders for treated and untreated
#separately, in order to achieve the conditional average treatement effect
#split sample:
df_t1 <- df[which(df$t==1),]
df_t0 <- df[which(df$t==0),]
est_t1 <- lm( y~x1+x2,data=df_t1)
est_t0 <- lm( y~x1+x2,data=df_t0)
yhat_t1 <- predict(est_t1)
yhat_t0 <- predict(est_t0)
effect <- mean(yhat_t1) - mean(yhat_t0)
#effect is biased!
yhat_t0_dft1 <- predict(est_t0, newdata=df_t1)
effect2 <- mean(yhat_t1) - mean(yhat_t0_dft1)
#correct treatment effect
#x-learner
yhat_t1_dft0 <- (predict(est_t1, newdata=df_t0))
effect2
effect3 <-  mean(yhat_t1_dft0) - mean(yhat_t0)
effect3
s_out <- S_RF(feat=df[,1:2], tr=df[,3], yobs=df[,4])
s_cate <- EstimateCate(s_out, df)
simulated_experiment <- simulate_causal_experiment(
ntrain = 1000,
ntest = 1000,
dim = 10)
x_cate <- EstimateCate(x_out, df[,2:3])
x_out <- X_RF(feat=df[,2:3], tr=df$t, yobs=df$y)
x_cate <- EstimateCate(x_out, df[,2:3])
s_cate <- EstimateCate(s_out, df[,2:3])
s_out <- S_RF(feat=df[,1:2], tr=df[,3], yobs=df[,4])
#df_test <- cbind(df[,2:3], t, y)
s_cate <- EstimateCate(s_out, df[,2:3])
t_out <- T_RF(feat=df[,2:3], tr=df$t, yobs=df$y)
t_cate <- EstimateCate(t_out, df[,2:3])
s_cate <- EstimateCate(s_out, df[,1:2])
s_out <- S_RF(feat=df[,1:2], tr=df[,3], yobs=df[,4])
#df_test <- cbind(df[,2:3], t, y)
s_cate <- EstimateCate(s_out, df[,1:2])
t_cate <- EstimateCate(t_out, df[,1:2])
t_out <- T_RF(feat=df[,1:2], tr=df[,3], yobs=df[,4])
t_cate <- EstimateCate(t_out, df[,1:2])
x_out <- X_RF(feat=df[,1:2], tr=df[,3], yobs=df[,4])
x_cate <- EstimateCate(x_out, df[,1:2])
s_cate
mean(s_cate)
mean(t_cate)
mean(x_cate)
EstimateCate
effect
effect3
effect2
est_t1
est_t0
mean(yhat_t1)
mean(yhat_t0)
effect
effect2
yhat_t1_dft0 <- predict(est_t1, newdata=df_t0)
effect2
effect3 <-  mean(yhat_t1_dft0) - mean(yhat_t0)
effect3
mean(yhat_t1)
mean(yhat_t0)
summary(df_t0)
est_t1 <- lm( y~x1+x2 -1,data=df_t1)
est_t0 <- lm( y~x1+x2 -1 ,data=df_t0)
yhat_t1 <- predict(est_t1)
yhat_t0 <- predict(est_t0)
yhat_t1
effect <- mean(yhat_t1) - mean(yhat_t0)
effect
effect2 <- mean(yhat_t1) - mean(yhat_t0_dft1)
effect2
effect
yhat_t0_dft1 <- predict(est_t0, newdata=df_t1)
effect2 <- mean(yhat_t1) - mean(yhat_t0_dft1)
effect2
est_t1 <- lm( y~x1+x2 -1,data=df_t1)
est_t0 <- lm( y~x1+x2 -1 ,data=df_t0)
yhat_t1 <- predict(est_t1)
yhat_t0 <- predict(est_t0)
effect <- mean(yhat_t1) - mean(yhat_t0)
#effect is biased! Which role plays constant?
#Wieso ist  mean(yhat_t0) negativ?
yhat_t0_dft1 <- predict(est_t0, newdata=df_t1)
effect2 <- mean(yhat_t1) - mean(yhat_t0_dft1)
effect
effect2
lm( y~x1+x2 -1,data=df_t1)
est_t1 <- lm( y~x1+x2,data=df_t1)
est_t0 <- lm( y~x1+x2,data=df_t0)
yhat_t1 <- predict(est_t1)
yhat_t0 <- predict(est_t0)
lm( y~t,data=df)
lm( y~x1+x2,data=df_t1)
lm( y~x1+x2,data=df_t0)
library(igraph)
install.packages("igraph")
library(igraph)
g<-graph.empty(n=2, directed=TRUE)
g
plot(g)
graph_from_literal("Covid 19"->"Mortality")
graph_from_literal("Covid 19"-+"Mortality")
g <- graph_from_literal("Covid 19"-+"Mortality")
plot(g)
install.packages("dagitty")
library(dagitty)
g2 <- dagitty("dag {
"Covid 19" -> "Mortality"
}")
plot( graphLayout( dag ) )
library(dagitty)
g2 <- dagitty("dag {
"Covid19" -> "Mortality"
}")
plot( graphLayout( dag ) )
library(dagitty)
g2 <- dagitty("dag {
Covid19 -> Mortality
}")
plot( graphLayout( dag ) )
plot( graphLayout( g2 ) )
install.packages("ggdag")
library(ggdag)
ggdag(g2) +
theme_dag()
ggdag(g2)
ggdag(g2) +
theme_dag()
library(dagitty)
g2 <- dagitty("dag {
X -> Y
}")
plot( graphLayout( g2 ) )
library(ggdag)
ggdag(g2) +
theme_dag()
library(dagitty)
g2 <- dagitty("dag {
X [pos="0,0"]
Y [pos="2,0"]
X -> Y
}")
plot( graphLayout( g2 ) )
g2 <- dagitty("dag {
X [pos="0,0"]
Y [pos="2,0"]
X -> Y
}")
g2 <- dag {
X [pos="0,0"]
Y [pos="2,0"]
X -> Y
}
dag {
X [pos="0,0"]
Y [pos="2,0"]
X -> Y
}
g2 <- dag{
X [pos="0,0"]
Y [pos="2,0"]
X -> Y
}
g2 <- dagitty(dag {
X [pos="0,0"]
Y [pos="2,0"]
X -> Y
})
g2 <- dagitty("dag {
X [pos="0,0"]
Y [pos="2,0"]
X -> Y
}")
plot( graphLayout( g2 ) )
g2 <- dagitty('dag {
X [pos="0,0"]
Y [pos="2,0"]
X -> Y
}')
plot( graphLayout( g2 ) )
g2 <- dagitty('dag {
X [pos="0,0"]
Y [pos="2,0"]
X -> Y
}')
plot( graphLayout( g2 ) )
g2 <- dagitty('dag {
X [pos="0,0"]
Y [pos="1,0"]
X -> Y
}')
plot( graphLayout( g2 ) )
g2 <- dagitty('dag {
X [pos="0,1"]
Y [pos="1,1"]
X -> Y
}')
plot( graphLayout( g2 ) )
plot(g2)
g2 <- dagitty('dag {
X [pos="0,1"]
Y [pos="1,1"]
P [pos="1.5,0.5"]
P -> {X, Y}
X -> Y
}')
plot(g2)
g2 <- dagitty('dag {
X [pos="0,1"]
Y [pos="1,1"]
P [pos="1.5,0.5"]
P -> {X Y}
X -> Y
}')
plot(g2)
g2 <- dagitty('dag {
X [pos="0,1"]
Y [pos="1,1"]
P [pos="0.5,1.5"]
P -> {X Y}
X -> Y
}')
plot(g2)
g2 <- dagitty('dag {
X [pos="0,1"]
Y [pos="1,1"]
P [pos="0.5,0.5"]
P -> {X Y}
X -> Y
}')
plot(g2)
g2 <- dagitty('dag {
X [pos="0,1"]
Y [pos="1,1"]
P [pos="0.5,0"]
P -> {X Y}
X -> Y
}')
plot(g2)
library(dagitty)
g <- dagitty('dag {
X0 -> {D, X1}
D -> {X1, Y}
X1 <- Y}')
#plot(g)
library(ggdag)
ggdag(g) +
theme_dag()
library(dagitty)
g <- dagitty('dag {
X0 -> {D X1}
D -> {X1 Y}
X1 <- Y}')
#plot(g)
library(ggdag)
ggdag(g) +
theme_dag()
library(dagitty)
g <- dagitty('dag {
X0 -> {D X1}
D -> {X1 Y}
X1 -> Y}')
#plot(g)
library(ggdag)
ggdag(g) +
theme_dag()
adjustmentSets(g, "D", "Y", type="all" )
adjustmentSets(g, "X1", "Y", type="all" )
c <- dagitty('dag {
X0 -> {KH Tod}
KH -> {Tod}
}')
ggdag(c) +
theme_dag()
c <- dagitty('dag {
{X0 X1} -> {KH Tod}
KH -> {Tod}
}')
ggdag(c) +
theme_dag()
adjustmentSets(c, "X0", "Tod", type="all" )
#Prädiktoren für Folgeerkrankungen von Diabetes infizieren
#Darf man auf D und X1 gleichzeit konditionieren?
library(dagitty)
g <- dagitty('dag {
X0 -> {D X1}
D -> {X1 Y}
X1 -> Y}')
#plot(g)
library(ggdag)
ggdag(g) +
theme_dag()
adjustmentSets(g, "X1", "Y", type="all" )
